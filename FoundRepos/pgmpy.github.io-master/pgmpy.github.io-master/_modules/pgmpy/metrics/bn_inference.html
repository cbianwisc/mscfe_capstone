<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pgmpy.metrics.bn_inference &mdash; pgmpy 0.1.19 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> pgmpy
          </a>
              <div class="version">
                dev branch
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../started/install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../started/contributing.html">Contributing to pgmpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../started/license.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Base Structures</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../base/base.html">Directed Acyclic Graph (DAG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../base/base.html#partial-directed-acyclic-graph-pdag">Partial Directed Acyclic Graph (PDAG)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../models/bayesiannetwork.html">Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/dbn.html">Dynamic Bayesian Network (DBN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/sem.html">Structural Equation Models (SEM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/naive.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/noisyor.html">NoisyOr Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/markovnetwork.html">Markov Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/junctiontree.html">Junction Tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/clustergraph.html">Cluster Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/factorgraph.html">Factor Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/markovchain.html">Markov Chain</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parameterization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/discrete.html">Discrete</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/discretize.html">Discretizing Methods</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exact Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/ve.html">Variable Elimination</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/ve.html#module-pgmpy.inference.EliminationOrder">Elimination Ordering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/bp.html">Belief Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/causal.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/mplp.html">MPLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/dbn_infer.html">Dynamic Bayesian Network Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/model_testing.html">Model Testing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Approximate Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../approx_infer/approx_infer.html">Approximate Inference Using Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../approx_infer/bn_sampling.html">Bayesian Model Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../approx_infer/gibbs.html">Gibbs Sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parameter Estimation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/mle.html">Maximum Likelihood Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/bayesian_est.html">Bayesian Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/em.html">Expectation Maximization (EM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/sem_estimator.html">Structural Equation Model Estimators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Structure Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/pc.html">PC (Constraint-Based Estimator)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/pc.html#module-pgmpy.estimators.CITests">Conditional Independence Tests for PC algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/hill.html">Hill Climb Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/hill.html#structure-score">Structure Score</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/tree.html">Tree Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/mmhc.html">Mmhc Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/exhaustive.html">Exhaustive Search</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Testing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../metrics/metrics.html">Metrics for testing models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Input/Output</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/bif.html">BIF (Bayesian Interchange Format)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/uai.html">UAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/xmlbif.html">XMLBIF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/pomdpx.html">PomdpX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/xmlbelief.html">XMLBeliefNetwork</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Example Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Earthquake.html">1. Example Using the Earthquake network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Monty%20Hall%20Problem.html">2. Monty Hall Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Creating%20a%20Discrete%20Bayesian%20Network.html">3. Creating discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Inference%20in%20Discrete%20Bayesian%20Networks.html">4. Inference in Discrete Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Causal%20Games.html">5. Causal Games</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Causal%20Inference.html">6. Causal Inference Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Learning%20Parameters%20in%20Discrete%20Bayesian%20Networks.html">7. Parameter Learning in Discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Structure%20Learning%20in%20Bayesian%20Networks.html">8. Structure Learning in Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Structure%20Learning%20with%20Chow-Liu.html">9. Learning Tree Structure from Data using the Chow-Liu Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Structure%20Learning%20with%20TAN.html">10. Learning Tree-augmented Naive Bayes (TAN) Structure from Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Simulating%20Data.html">11. Normal Bayesian Network (no time variation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Extending%20pgmpy.html">12. Extending pgmpy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/1.%20Introduction%20to%20Probabilistic%20Graphical%20Models.html">1. Introduction to Probabilitic Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/2.%20Bayesian%20Networks.html">2. Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/3.%20Causal%20Bayesian%20Networks.html">3. Causal Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/4.%20Markov%20Models.html">4. Markov Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/5.%20Exact%20Inference%20in%20Graphical%20Models.html">5. Exact Inference in Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/6.%20Approximate%20Inference%20in%20Graphical%20Models.html">6. Approximate Inference in Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/7.%20Parameterizing%20with%20Continuous%20Variables.html">7. Parameterizing with Continuous Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/8.%20Sampling%20Algorithms.html">8. Sampling In Continuous Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html">9. Reading and Writing from pgmpy file formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/10.%20Learning%20Bayesian%20Networks%20from%20Data.html">10. Learning Bayesian Networks from Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../detailed_notebooks/11.%20A%20Bayesian%20Network%20to%20model%20the%20influence%20of%20energy%20consumption%20on%20greenhouse%20gases%20in%20Italy.html">11. A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">pgmpy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pgmpy.metrics.bn_inference</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pgmpy.metrics.bn_inference</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">BayesianModelInference</span>


<div class="viewcode-block" id="BayesianModelProbability"><a class="viewcode-back" href="../../../exact_infer/model_testing.html#pgmpy.metrics.bn_inference.BayesianModelProbability">[docs]</a><span class="k">class</span> <span class="nc">BayesianModelProbability</span><span class="p">(</span><span class="n">BayesianModelInference</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class to calculate probability (pmf) values specific to Bayesian Models</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Class to calculate probability (pmf) values specific to Bayesian Models</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model: Bayesian Model</span>
<span class="sd">            model on which inference queries will be computed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BayesianModelProbability</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_probability_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">ordering</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the log probability of each datapoint for a specific node.</span>

<span class="sd">        Internal function used by log_probability().</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: array_like, shape (n_samples, n_features)</span>
<span class="sd">            List of n_features-dimensional data points.  Each row</span>
<span class="sd">            corresponds to a single data point.</span>

<span class="sd">        ordering: list</span>
<span class="sd">            ordering of columns in data, used by the Bayesian model.</span>
<span class="sd">            default is topological ordering used by model.</span>

<span class="sd">        node: Bayesian Model Node</span>
<span class="sd">            node from the Bayesian network.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Log probability of node: np.array (n_samples,)</span>
<span class="sd">            The array of log(density) evaluations. These are normalized to be</span>
<span class="sd">            probability densities, so values will be low for high-dimensional</span>
<span class="sd">            data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">vec_translate</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">my_dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">my_dict</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">)(</span><span class="n">a</span><span class="p">)</span>

        <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="c1"># variable to probe: data[n], where n is the node number</span>
        <span class="n">current</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">current_idx</span> <span class="o">=</span> <span class="n">ordering</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">current</span><span class="p">)</span>
        <span class="n">current_val</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">current_idx</span><span class="p">]</span>
        <span class="n">current_no</span> <span class="o">=</span> <span class="n">vec_translate</span><span class="p">(</span><span class="n">current_val</span><span class="p">,</span> <span class="n">cpd</span><span class="o">.</span><span class="n">name_to_no</span><span class="p">[</span><span class="n">current</span><span class="p">])</span>

        <span class="c1"># conditional dependencies E of the probed variable</span>
        <span class="n">evidence</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">[:</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">evidence_idx</span> <span class="o">=</span> <span class="p">[</span><span class="n">ordering</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">ev</span><span class="p">)</span> <span class="k">for</span> <span class="n">ev</span> <span class="ow">in</span> <span class="n">evidence</span><span class="p">]</span>
        <span class="n">evidence_val</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="n">evidence_idx</span><span class="p">]</span>
        <span class="n">evidence_no</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">evidence_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ev</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">evidence</span><span class="p">):</span>
            <span class="n">evidence_no</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">vec_translate</span><span class="p">(</span><span class="n">evidence_val</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">cpd</span><span class="o">.</span><span class="n">name_to_no</span><span class="p">[</span><span class="n">ev</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">evidence</span><span class="p">:</span>
            <span class="c1"># there are conditional dependencies E for data[n] for this node</span>
            <span class="c1"># Here we retrieve the array: p(x[n]|E). We do this for each x in data.</span>
            <span class="c1"># We pick the specific node value from the arrays below.</span>

            <span class="n">unique</span><span class="p">,</span> <span class="n">inverse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">evidence_no</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">unique</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">unique</span><span class="p">]</span>
            <span class="n">state_to_index</span><span class="p">,</span> <span class="n">index_to_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_compute_reduce_maps</span><span class="p">(</span>
                <span class="n">variable</span><span class="o">=</span><span class="n">node</span><span class="p">,</span> <span class="n">state_combinations</span><span class="o">=</span><span class="n">unique</span>
            <span class="p">)</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span><span class="n">index_to_weight</span><span class="p">[</span><span class="n">state_to_index</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">u</span><span class="p">)]]</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">unique</span><span class="p">]</span>
            <span class="p">)[</span><span class="n">inverse</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># there are NO conditional dependencies for this node</span>
            <span class="c1"># retrieve array: p(x[n]).  We do this for each x in data.</span>
            <span class="c1"># We pick the specific node value from the arrays below.</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">cpd</span><span class="o">.</span><span class="n">values</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

        <span class="c1"># pick the specific node value x[n] from the array p(x[n]|E) or p(x[n])</span>
        <span class="c1"># We do this for each x in data.</span>
        <span class="n">probability_node</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">cn</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cn</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">current_no</span><span class="p">)])</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probability_node</span><span class="p">)</span>

<div class="viewcode-block" id="BayesianModelProbability.log_probability"><a class="viewcode-back" href="../../../exact_infer/model_testing.html#pgmpy.metrics.bn_inference.BayesianModelProbability.log_probability">[docs]</a>    <span class="k">def</span> <span class="nf">log_probability</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">ordering</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the logarithmic probability of each point in a data set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: pandas dataframe OR array_like, shape (n_samples, n_features)</span>
<span class="sd">            List of n_features-dimensional data points.  Each row</span>
<span class="sd">            corresponds to a single data point.</span>

<span class="sd">        ordering: list</span>
<span class="sd">            ordering of columns in data, used by the Bayesian model.</span>
<span class="sd">            default is topological ordering used by model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Log probability of each datapoint: np.array (n_samples,)</span>
<span class="sd">            The array of log(density) evaluations. These are normalized to be</span>
<span class="sd">            probability densities, so values will be low for high-dimensional</span>
<span class="sd">            data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="c1"># use numpy array from now on.</span>
            <span class="n">ordering</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="n">ordering</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ordering</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">topological_order</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">ordering</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

        <span class="n">logp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_probability_node</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ordering</span><span class="p">,</span> <span class="n">node</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">ordering</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">logp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="BayesianModelProbability.score"><a class="viewcode-back" href="../../../exact_infer/model_testing.html#pgmpy.metrics.bn_inference.BayesianModelProbability.score">[docs]</a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">ordering</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the total log probability density under the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: pandas dataframe OR array_like, shape (n_samples, n_features)</span>
<span class="sd">            List of n_features-dimensional data points.  Each row</span>
<span class="sd">            corresponds to a single data point.</span>

<span class="sd">        ordering: list</span>
<span class="sd">            ordering of columns in data, used by the Bayesian model.</span>
<span class="sd">            default is topological ordering used by model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Log-likelihood of data: float</span>
<span class="sd">            This is normalized to be a probability density, so the value</span>
<span class="sd">            will be low for high-dimensional data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probability</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ordering</span><span class="p">))</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Ankur Ankan.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-177825880-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-177825880-1', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>